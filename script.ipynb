{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "4fa69427",
      "metadata": {},
      "source": [
        "# McHacks 26 - Bot or Not\n",
        "\n",
        "### Imports"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 62,
      "id": "25e59269",
      "metadata": {},
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import matplotlib as plt\n",
        "from pathlib import Path\n",
        "import json\n",
        "import pandas as pd\n",
        "import re\n",
        "from transformers import AutoTokenizer\n",
        "from sklearn.preprocessing import StandardScaler"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "3c78ef1e",
      "metadata": {},
      "source": [
        "### Data processing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 63,
      "id": "071ab039",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "EN sources: ['dataset.posts&users.30.json', 'dataset.posts&users.32.json']\n",
            "EN posts: 15,765 users: 546 bot_ids: 129\n",
            "FR sources: ['dataset.posts&users.31.json', 'dataset.posts&users.33.json']\n",
            "FR posts: 9,004 users: 343 bot_ids: 55\n"
          ]
        }
      ],
      "source": [
        "DATA_DIR = Path(\"data\")\n",
        "\n",
        "def get_version(path):\n",
        "    try:\n",
        "        return int(path.stem.split(\".\")[-1])\n",
        "    except ValueError:\n",
        "        return None\n",
        "\n",
        "posts_users_files = sorted(DATA_DIR.glob(\"dataset.posts&users.*.json\"), key=get_version)\n",
        "if not posts_users_files:\n",
        "    raise FileNotFoundError(\"No dataset.posts&users.*.json files found in data/\")\n",
        "\n",
        "combined = {}\n",
        "bots_by_lang = {}\n",
        "\n",
        "for path in posts_users_files:\n",
        "    with path.open() as f:\n",
        "        data = json.load(f)\n",
        "    lang = data.get(\"lang\")\n",
        "\n",
        "    combined.setdefault(lang, {\"posts\": [], \"users\": [], \"sources\": []})\n",
        "    combined[lang][\"posts\"].extend(data.get(\"posts\", []))\n",
        "    combined[lang][\"users\"].extend(data.get(\"users\", []))\n",
        "    combined[lang][\"sources\"].append(path.name)\n",
        "\n",
        "    version = get_version(path)\n",
        "    if version is not None:\n",
        "        bots_path = DATA_DIR / f\"dataset.bots.{version}.txt\"\n",
        "        if bots_path.exists():\n",
        "            bots_by_lang.setdefault(lang, set()).update(bots_path.read_text().splitlines())\n",
        "\n",
        "posts_en = pd.DataFrame(combined.get(\"en\", {}).get(\"posts\", []))\n",
        "users_en = pd.DataFrame(combined.get(\"en\", {}).get(\"users\", []))\n",
        "bot_ids_en = bots_by_lang.get(\"en\", set())\n",
        "if not users_en.empty:\n",
        "    users_en[\"is_bot\"] = users_en[\"id\"].isin(bot_ids_en)\n",
        "\n",
        "posts_fr = pd.DataFrame(combined.get(\"fr\", {}).get(\"posts\", []))\n",
        "users_fr = pd.DataFrame(combined.get(\"fr\", {}).get(\"users\", []))\n",
        "bot_ids_fr = bots_by_lang.get(\"fr\", set())\n",
        "if not users_fr.empty:\n",
        "    users_fr[\"is_bot\"] = users_fr[\"id\"].isin(bot_ids_fr)\n",
        "\n",
        "print(\"EN sources:\", combined.get(\"en\", {}).get(\"sources\", []))\n",
        "print(f\"EN posts: {len(posts_en):,} users: {len(users_en):,} bot_ids: {len(bot_ids_en):,}\")\n",
        "print(\"FR sources:\", combined.get(\"fr\", {}).get(\"sources\", []))\n",
        "print(f\"FR posts: {len(posts_fr):,} users: {len(users_fr):,} bot_ids: {len(bot_ids_fr):,}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "2e34ec8c",
      "metadata": {},
      "source": [
        "### Experiment parameters"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 64,
      "id": "926640c2",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Experiment config loaded:\n",
            "- tokenizer_name: vinai/bertweet-base\n",
            "- max_length: 96\n",
            "- dedupe_users: True\n",
            "- dedupe_posts: True\n",
            "- scale_meta_features: True\n",
            "- use_topic_features: True\n",
            "- topic_match_mode: word\n",
            "- test_size: 0.2\n",
            "- random_seed: 42\n",
            "- validation_split: 0.15\n",
            "- epochs: 8\n",
            "- batch_size: 128\n",
            "- learning_rate: 0.001\n",
            "- prediction_threshold: 0.62\n",
            "- use_threshold_search: True\n",
            "- threshold_search_min: 0.1\n",
            "- threshold_search_max: 0.9\n",
            "- threshold_search_steps: 161\n",
            "- account_decision_rule: mean\n",
            "- split_by_author: True\n",
            "- ensemble_seeds: [13, 29, 42, 73, 101]\n",
            "- ensemble_aggregation: mean\n",
            "- use_second_stage_account_model: True\n",
            "- second_stage_learning_rate: 0.05\n",
            "- second_stage_max_iter: 300\n",
            "- second_stage_max_depth: 4\n",
            "- second_stage_l2: 0.2\n",
            "- second_stage_use_balanced_weights: True\n",
            "- use_class_weights: False\n",
            "- embedding_dim: 96\n",
            "- gru_units: 48\n",
            "- aux_dense_units: 32\n",
            "- head_dense_units: 48\n",
            "- dropout_text: 0.4\n",
            "- dropout_aux: 0.3\n",
            "- dropout_head: 0.4\n",
            "- early_stopping_patience: 1\n",
            "- reduce_lr_patience: 1\n",
            "- reduce_lr_factor: 0.5\n",
            "- reduce_lr_min_lr: 1e-05\n"
          ]
        }
      ],
      "source": [
        "EXPERIMENT_CONFIG = {\n",
        "    \"tokenizer_name\": \"vinai/bertweet-base\",\n",
        "    \"max_length\": 96,\n",
        "    \"dedupe_users\": True,\n",
        "    \"dedupe_posts\": True,\n",
        "    \"scale_meta_features\": True,\n",
        "    \"use_topic_features\": True,\n",
        "    \"topic_match_mode\": \"word\",  # options: \"contains\", \"word\"\n",
        "    \"test_size\": 0.20,\n",
        "    \"random_seed\": 42,\n",
        "    \"validation_split\": 0.15,\n",
        "    \"epochs\": 8,\n",
        "    \"batch_size\": 128,\n",
        "    \"learning_rate\": 0.001,\n",
        "    \"prediction_threshold\": 0.62,\n",
        "    \"use_threshold_search\": True,\n",
        "    \"threshold_search_min\": 0.10,\n",
        "    \"threshold_search_max\": 0.90,\n",
        "    \"threshold_search_steps\": 161,\n",
        "    \"account_decision_rule\": \"mean\",  # options: \"mean\", \"any\"\n",
        "    \"split_by_author\": True,\n",
        "    \"ensemble_seeds\": [13, 29, 42, 73, 101],\n",
        "    \"ensemble_aggregation\": \"mean\",  # options: \"mean\", \"median\"\n",
        "    \"use_second_stage_account_model\": True,\n",
        "    \"second_stage_learning_rate\": 0.05,\n",
        "    \"second_stage_max_iter\": 300,\n",
        "    \"second_stage_max_depth\": 4,\n",
        "    \"second_stage_l2\": 0.2,\n",
        "    \"second_stage_use_balanced_weights\": True,\n",
        "    \"use_class_weights\": False,\n",
        "    \"embedding_dim\": 96,\n",
        "    \"gru_units\": 48,\n",
        "    \"aux_dense_units\": 32,\n",
        "    \"head_dense_units\": 48,\n",
        "    \"dropout_text\": 0.40,\n",
        "    \"dropout_aux\": 0.30,\n",
        "    \"dropout_head\": 0.40,\n",
        "    \"early_stopping_patience\": 1,\n",
        "    \"reduce_lr_patience\": 1,\n",
        "    \"reduce_lr_factor\": 0.50,\n",
        "    \"reduce_lr_min_lr\": 1e-5,\n",
        "}\n",
        "\n",
        "print(\"Experiment config loaded:\")\n",
        "for key, value in EXPERIMENT_CONFIG.items():\n",
        "    print(f\"- {key}: {value}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "37411cfe",
      "metadata": {},
      "source": [
        "### Tokenizing the text"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 65,
      "id": "a1288615",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Tokenizer: vinai/bertweet-base\n",
            "English labeled posts: 15,765\n",
            "Token tensor shape: (15765, 96)\n",
            "Meta feature shape: (15765, 7), label shape: (15765,)\n",
            "Dedupe users/posts: True/True\n",
            "Scale metadata features: True\n"
          ]
        }
      ],
      "source": [
        "import re\n",
        "\n",
        "try:\n",
        "    from transformers import AutoTokenizer\n",
        "except ImportError as exc:\n",
        "    raise ImportError(\"Install transformers first: pip install transformers\") from exc\n",
        "\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "if \"EXPERIMENT_CONFIG\" not in globals():\n",
        "    raise ValueError(\"Run the Experiment parameters cell first.\")\n",
        "\n",
        "TOKENIZER_NAME = str(EXPERIMENT_CONFIG[\"tokenizer_name\"])\n",
        "MAX_LENGTH = int(EXPERIMENT_CONFIG[\"max_length\"])\n",
        "DEDUPE_USERS = bool(EXPERIMENT_CONFIG[\"dedupe_users\"])\n",
        "DEDUPE_POSTS = bool(EXPERIMENT_CONFIG[\"dedupe_posts\"])\n",
        "SCALE_META_FEATURES = bool(EXPERIMENT_CONFIG[\"scale_meta_features\"])\n",
        "\n",
        "def clean_text(text):\n",
        "    if not isinstance(text, str):\n",
        "        return \"\"\n",
        "    text = text.replace(\"\\n\", \" \").strip()\n",
        "    text = re.sub(r\"\\s+\", \" \", text)\n",
        "    return text\n",
        "\n",
        "def add_text_features(df):\n",
        "    out = df.copy()\n",
        "    out[\"text_clean\"] = out[\"text\"].fillna(\"\").map(clean_text)\n",
        "    out[\"char_count\"] = out[\"text_clean\"].str.len()\n",
        "    out[\"word_count\"] = out[\"text_clean\"].str.split().str.len()\n",
        "    out[\"url_count\"] = out[\"text_clean\"].str.count(r\"https?://\\S+|www\\.\\S+\")\n",
        "    out[\"mention_count\"] = out[\"text_clean\"].str.count(r\"@\\w+\")\n",
        "    out[\"hashtag_count\"] = out[\"text_clean\"].str.count(r\"#\\w+\")\n",
        "    out[\"exclamation_count\"] = out[\"text_clean\"].str.count(r\"!\")\n",
        "    out[\"question_count\"] = out[\"text_clean\"].str.count(r\"\\?\")\n",
        "    return out\n",
        "\n",
        "if posts_en.empty or users_en.empty:\n",
        "    raise ValueError(\"Run the data processing cell first to load English data.\")\n",
        "\n",
        "users_en_labeled = (\n",
        "    users_en.drop_duplicates(subset=\"id\", keep=\"last\").copy()\n",
        "    if DEDUPE_USERS\n",
        "    else users_en.copy()\n",
        ")\n",
        "posts_en_unique = (\n",
        "    posts_en.drop_duplicates(subset=\"id\", keep=\"last\").copy()\n",
        "    if DEDUPE_POSTS\n",
        "    else posts_en.copy()\n",
        ")\n",
        "\n",
        "label_map_en = users_en_labeled.set_index(\"id\")[\"is_bot\"]\n",
        "train_en = posts_en_unique.copy()\n",
        "train_en[\"is_bot\"] = train_en[\"author_id\"].map(label_map_en)\n",
        "train_en = train_en.dropna(subset=[\"is_bot\"]).copy()\n",
        "train_en[\"is_bot\"] = train_en[\"is_bot\"].astype(\"int64\")\n",
        "\n",
        "train_en = add_text_features(train_en)\n",
        "\n",
        "tokenizer = AutoTokenizer.from_pretrained(TOKENIZER_NAME, use_fast=True)\n",
        "encodings_en = tokenizer(\n",
        "    train_en[\"text_clean\"].tolist(),\n",
        "    truncation=True,\n",
        "    padding=\"max_length\",\n",
        "    max_length=MAX_LENGTH,\n",
        "    return_attention_mask=True,\n",
        ")\n",
        "\n",
        "feature_cols_en = [\n",
        "    \"char_count\",\n",
        "    \"word_count\",\n",
        "    \"url_count\",\n",
        "    \"mention_count\",\n",
        "    \"hashtag_count\",\n",
        "    \"exclamation_count\",\n",
        "    \"question_count\",\n",
        "]\n",
        "X_meta_en = train_en[feature_cols_en].to_numpy(dtype=np.float32)\n",
        "y_en = train_en[\"is_bot\"].to_numpy(dtype=np.int64)\n",
        "\n",
        "if SCALE_META_FEATURES:\n",
        "    scaler_en = StandardScaler()\n",
        "    X_meta_en_scaled = scaler_en.fit_transform(X_meta_en).astype(np.float32)\n",
        "else:\n",
        "    scaler_en = None\n",
        "    X_meta_en_scaled = X_meta_en.copy()\n",
        "\n",
        "print(f\"Tokenizer: {TOKENIZER_NAME}\")\n",
        "print(f\"English labeled posts: {len(train_en):,}\")\n",
        "print(f\"Token tensor shape: {np.asarray(encodings_en['input_ids']).shape}\")\n",
        "print(f\"Meta feature shape: {X_meta_en_scaled.shape}, label shape: {y_en.shape}\")\n",
        "print(f\"Dedupe users/posts: {DEDUPE_USERS}/{DEDUPE_POSTS}\")\n",
        "print(f\"Scale metadata features: {SCALE_META_FEATURES}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "251cded3",
      "metadata": {},
      "source": [
        "## Train-Test split for model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 66,
      "id": "c8c62216",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/8\n",
            "\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 89ms/step - accuracy: 0.7451 - auc: 0.7613 - loss: 0.5348 - val_accuracy: 0.8692 - val_auc: 0.8204 - val_loss: 0.3839 - learning_rate: 0.0010\n",
            "Epoch 2/8\n",
            "\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 110ms/step - accuracy: 0.8964 - auc: 0.9100 - loss: 0.2980 - val_accuracy: 0.8707 - val_auc: 0.8105 - val_loss: 0.3998 - learning_rate: 0.0010\n",
            "Split mode: author\n",
            "Topic features enabled: True\n",
            "Topic match mode: word\n",
            "Account decision rule: mean\n",
            "Topic columns: ['topic_pop', 'topic_nba', 'topic_movies', 'topic_nhl']\n",
            "Split sizes (fit/val/test posts): 10318/2041/3406\n",
            "Split sizes (fit/val/test accounts): 370/66/110\n",
            "Default threshold from config: 0.6200\n",
            "Selected threshold used on test: 0.2650\n",
            "Best validation score from threshold search: 46\n",
            "Test Accuracy (post-level): 0.8417\n",
            "Test ROC-AUC (post-level): 0.8768\n",
            "Test account score @ selected threshold -> score=62, TP=22, FN=4, FP=11, accounts=110\n",
            "Test account score @ config threshold -> score=39, TP=13, FN=13, FP=0, accounts=110\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0     0.9132    0.8659    0.8889      2490\n",
            "           1     0.6804    0.7762    0.7251       916\n",
            "\n",
            "    accuracy                         0.8417      3406\n",
            "   macro avg     0.7968    0.8210    0.8070      3406\n",
            "weighted avg     0.8506    0.8417    0.8449      3406\n",
            "\n"
          ]
        }
      ],
      "source": [
        "import re\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score, classification_report, roc_auc_score\n",
        "from sklearn.utils.class_weight import compute_class_weight\n",
        "\n",
        "try:\n",
        "    import tensorflow as tf\n",
        "except ImportError as exc:\n",
        "    raise ImportError(\"Install tensorflow first: pip install tensorflow\") from exc\n",
        "\n",
        "if \"EXPERIMENT_CONFIG\" not in globals():\n",
        "    raise ValueError(\"Run the Experiment parameters cell first.\")\n",
        "\n",
        "TEST_SIZE = float(EXPERIMENT_CONFIG[\"test_size\"])\n",
        "RANDOM_SEED = int(EXPERIMENT_CONFIG[\"random_seed\"])\n",
        "VALIDATION_SPLIT = float(EXPERIMENT_CONFIG[\"validation_split\"])\n",
        "EPOCHS = int(EXPERIMENT_CONFIG[\"epochs\"])\n",
        "BATCH_SIZE = int(EXPERIMENT_CONFIG[\"batch_size\"])\n",
        "LEARNING_RATE = float(EXPERIMENT_CONFIG[\"learning_rate\"])\n",
        "PREDICTION_THRESHOLD = float(EXPERIMENT_CONFIG[\"prediction_threshold\"])\n",
        "USE_CLASS_WEIGHTS = bool(EXPERIMENT_CONFIG[\"use_class_weights\"])\n",
        "USE_TOPIC_FEATURES = bool(EXPERIMENT_CONFIG[\"use_topic_features\"])\n",
        "TOPIC_MATCH_MODE = str(EXPERIMENT_CONFIG[\"topic_match_mode\"])\n",
        "SPLIT_BY_AUTHOR = bool(EXPERIMENT_CONFIG.get(\"split_by_author\", True))\n",
        "\n",
        "USE_THRESHOLD_SEARCH = bool(EXPERIMENT_CONFIG.get(\"use_threshold_search\", False))\n",
        "THRESHOLD_SEARCH_MIN = float(EXPERIMENT_CONFIG.get(\"threshold_search_min\", 0.10))\n",
        "THRESHOLD_SEARCH_MAX = float(EXPERIMENT_CONFIG.get(\"threshold_search_max\", 0.90))\n",
        "THRESHOLD_SEARCH_STEPS = int(EXPERIMENT_CONFIG.get(\"threshold_search_steps\", 81))\n",
        "ACCOUNT_DECISION_RULE = str(EXPERIMENT_CONFIG.get(\"account_decision_rule\", \"mean\"))\n",
        "\n",
        "EMBEDDING_DIM = int(EXPERIMENT_CONFIG[\"embedding_dim\"])\n",
        "GRU_UNITS = int(EXPERIMENT_CONFIG[\"gru_units\"])\n",
        "AUX_DENSE_UNITS = int(EXPERIMENT_CONFIG[\"aux_dense_units\"])\n",
        "HEAD_DENSE_UNITS = int(EXPERIMENT_CONFIG[\"head_dense_units\"])\n",
        "DROPOUT_TEXT = float(EXPERIMENT_CONFIG[\"dropout_text\"])\n",
        "DROPOUT_AUX = float(EXPERIMENT_CONFIG[\"dropout_aux\"])\n",
        "DROPOUT_HEAD = float(EXPERIMENT_CONFIG[\"dropout_head\"])\n",
        "\n",
        "EARLY_STOPPING_PATIENCE = int(EXPERIMENT_CONFIG[\"early_stopping_patience\"])\n",
        "REDUCE_LR_PATIENCE = int(EXPERIMENT_CONFIG[\"reduce_lr_patience\"])\n",
        "REDUCE_LR_FACTOR = float(EXPERIMENT_CONFIG[\"reduce_lr_factor\"])\n",
        "REDUCE_LR_MIN_LR = float(EXPERIMENT_CONFIG[\"reduce_lr_min_lr\"])\n",
        "\n",
        "if not (0.0 < TEST_SIZE < 1.0):\n",
        "    raise ValueError(\"test_size must be between 0 and 1.\")\n",
        "if not (0.0 <= VALIDATION_SPLIT < 1.0):\n",
        "    raise ValueError(\"validation_split must be in [0, 1).\")\n",
        "if TOPIC_MATCH_MODE not in {\"contains\", \"word\"}:\n",
        "    raise ValueError('topic_match_mode must be \"contains\" or \"word\".')\n",
        "if ACCOUNT_DECISION_RULE not in {\"mean\", \"any\"}:\n",
        "    raise ValueError('account_decision_rule must be \"mean\" or \"any\".')\n",
        "if USE_THRESHOLD_SEARCH:\n",
        "    if not (0.0 < THRESHOLD_SEARCH_MIN < 1.0 and 0.0 < THRESHOLD_SEARCH_MAX < 1.0):\n",
        "        raise ValueError(\"threshold_search_min and threshold_search_max must be in (0, 1).\")\n",
        "    if THRESHOLD_SEARCH_MIN >= THRESHOLD_SEARCH_MAX:\n",
        "        raise ValueError(\"threshold_search_min must be smaller than threshold_search_max.\")\n",
        "    if THRESHOLD_SEARCH_STEPS < 2:\n",
        "        raise ValueError(\"threshold_search_steps must be >= 2.\")\n",
        "\n",
        "\n",
        "def load_english_topic_keywords():\n",
        "    topic_keywords = {}\n",
        "    for source_name in combined.get(\"en\", {}).get(\"sources\", []):\n",
        "        source_path = DATA_DIR / source_name\n",
        "        with source_path.open() as f:\n",
        "            payload = json.load(f)\n",
        "        for topic_item in payload.get(\"metadata\", {}).get(\"topics\", []):\n",
        "            topic = str(topic_item.get(\"topic\", \"\")).strip().lower()\n",
        "            if not topic:\n",
        "                continue\n",
        "            keywords = {\n",
        "                str(keyword).strip().lower()\n",
        "                for keyword in topic_item.get(\"keywords\", [])\n",
        "                if str(keyword).strip()\n",
        "            }\n",
        "            keywords.add(topic)\n",
        "            topic_keywords.setdefault(topic, set()).update(keywords)\n",
        "    return {topic: sorted(values, key=len, reverse=True) for topic, values in topic_keywords.items()}\n",
        "\n",
        "\n",
        "def add_topic_features(df, topic_keywords, match_mode):\n",
        "    out = df.copy()\n",
        "    text_lower = out[\"text_clean\"].str.lower()\n",
        "    topic_cols = []\n",
        "    for topic, keywords in topic_keywords.items():\n",
        "        col = f\"topic_{topic}\"\n",
        "        topic_cols.append(col)\n",
        "        if not keywords:\n",
        "            out[col] = 0\n",
        "            continue\n",
        "        if match_mode == \"word\":\n",
        "            pattern = \"|\".join(rf\"\\\\b{re.escape(keyword)}\\\\b\" for keyword in keywords)\n",
        "        else:\n",
        "            pattern = \"|\".join(re.escape(keyword) for keyword in keywords)\n",
        "        out[col] = text_lower.str.contains(pattern, regex=True).astype(np.int8)\n",
        "    return out, topic_cols\n",
        "\n",
        "\n",
        "def compute_account_score(author_ids, true_labels, pred_probs, threshold, decision_rule):\n",
        "    tmp = pd.DataFrame(\n",
        "        {\n",
        "            \"author_id\": author_ids,\n",
        "            \"true_is_bot\": np.asarray(true_labels, dtype=np.int64),\n",
        "            \"pred_prob\": np.asarray(pred_probs, dtype=np.float32),\n",
        "        }\n",
        "    )\n",
        "    tmp[\"pred_post\"] = (tmp[\"pred_prob\"] >= threshold).astype(np.int64)\n",
        "\n",
        "    account = (\n",
        "        tmp.groupby(\"author_id\", as_index=False)\n",
        "        .agg(\n",
        "            true_is_bot=(\"true_is_bot\", \"max\"),\n",
        "            mean_prob=(\"pred_prob\", \"mean\"),\n",
        "            any_pred=(\"pred_post\", \"max\"),\n",
        "        )\n",
        "    )\n",
        "\n",
        "    if decision_rule == \"any\":\n",
        "        account[\"pred_is_bot\"] = account[\"any_pred\"].astype(np.int64)\n",
        "    else:\n",
        "        account[\"pred_is_bot\"] = (account[\"mean_prob\"] >= threshold).astype(np.int64)\n",
        "\n",
        "    tp_accounts = int(((account[\"true_is_bot\"] == 1) & (account[\"pred_is_bot\"] == 1)).sum())\n",
        "    fn_accounts = int(((account[\"true_is_bot\"] == 1) & (account[\"pred_is_bot\"] == 0)).sum())\n",
        "    fp_accounts = int(((account[\"true_is_bot\"] == 0) & (account[\"pred_is_bot\"] == 1)).sum())\n",
        "\n",
        "    score = (4 * tp_accounts) - (1 * fn_accounts) - (2 * fp_accounts)\n",
        "    return score, tp_accounts, fn_accounts, fp_accounts, len(account)\n",
        "\n",
        "\n",
        "def predict_for_indices(model, post_indices):\n",
        "    if len(post_indices) == 0:\n",
        "        return np.array([], dtype=np.float32)\n",
        "    return model.predict(\n",
        "        {\n",
        "            \"input_ids\": input_ids_en[post_indices],\n",
        "            \"attention_mask\": attention_mask_en[post_indices],\n",
        "            \"aux_features\": X_aux_en[post_indices],\n",
        "        },\n",
        "        verbose=0,\n",
        "    ).ravel()\n",
        "\n",
        "\n",
        "if USE_TOPIC_FEATURES:\n",
        "    topic_keywords_en = load_english_topic_keywords()\n",
        "    train_en_model, topic_feature_cols_en = add_topic_features(train_en, topic_keywords_en, TOPIC_MATCH_MODE)\n",
        "else:\n",
        "    train_en_model = train_en.copy()\n",
        "    topic_feature_cols_en = []\n",
        "\n",
        "input_ids_en = np.asarray(encodings_en[\"input_ids\"], dtype=np.int32)\n",
        "attention_mask_en = np.asarray(encodings_en[\"attention_mask\"], dtype=np.float32)\n",
        "X_topic_en = (\n",
        "    train_en_model[topic_feature_cols_en].to_numpy(dtype=np.float32)\n",
        "    if topic_feature_cols_en\n",
        "    else np.zeros((len(train_en_model), 0), dtype=np.float32)\n",
        ")\n",
        "X_aux_en = np.concatenate([X_meta_en_scaled, X_topic_en], axis=1)\n",
        "\n",
        "all_post_idx = np.arange(len(y_en))\n",
        "\n",
        "if SPLIT_BY_AUTHOR:\n",
        "    author_labels_df = (\n",
        "        train_en_model.groupby(\"author_id\", as_index=False)[\"is_bot\"]\n",
        "        .max()\n",
        "        .rename(columns={\"is_bot\": \"account_is_bot\"})\n",
        "    )\n",
        "    all_authors = author_labels_df[\"author_id\"].to_numpy()\n",
        "    all_author_labels = author_labels_df[\"account_is_bot\"].to_numpy(dtype=np.int64)\n",
        "\n",
        "    train_authors, test_authors = train_test_split(\n",
        "        all_authors,\n",
        "        test_size=TEST_SIZE,\n",
        "        random_state=RANDOM_SEED,\n",
        "        stratify=all_author_labels,\n",
        "    )\n",
        "\n",
        "    if VALIDATION_SPLIT > 0:\n",
        "        train_author_labels = (\n",
        "            author_labels_df.set_index(\"author_id\").loc[train_authors, \"account_is_bot\"].to_numpy(dtype=np.int64)\n",
        "        )\n",
        "        fit_authors, val_authors = train_test_split(\n",
        "            train_authors,\n",
        "            test_size=VALIDATION_SPLIT,\n",
        "            random_state=RANDOM_SEED,\n",
        "            stratify=train_author_labels,\n",
        "        )\n",
        "    else:\n",
        "        fit_authors = train_authors\n",
        "        val_authors = np.array([], dtype=all_authors.dtype)\n",
        "\n",
        "    fit_author_set = set(fit_authors.tolist())\n",
        "    val_author_set = set(val_authors.tolist())\n",
        "    test_author_set = set(test_authors.tolist())\n",
        "\n",
        "    fit_idx = np.flatnonzero(train_en_model[\"author_id\"].isin(fit_author_set).to_numpy())\n",
        "    val_idx = np.flatnonzero(train_en_model[\"author_id\"].isin(val_author_set).to_numpy())\n",
        "    test_idx = np.flatnonzero(train_en_model[\"author_id\"].isin(test_author_set).to_numpy())\n",
        "    split_mode = \"author\"\n",
        "else:\n",
        "    train_idx, test_idx = train_test_split(\n",
        "        all_post_idx,\n",
        "        test_size=TEST_SIZE,\n",
        "        random_state=RANDOM_SEED,\n",
        "        stratify=y_en,\n",
        "    )\n",
        "\n",
        "    if VALIDATION_SPLIT > 0:\n",
        "        fit_idx, val_idx = train_test_split(\n",
        "            train_idx,\n",
        "            test_size=VALIDATION_SPLIT,\n",
        "            random_state=RANDOM_SEED,\n",
        "            stratify=y_en[train_idx],\n",
        "        )\n",
        "    else:\n",
        "        fit_idx = train_idx\n",
        "        val_idx = np.array([], dtype=np.int64)\n",
        "\n",
        "    split_mode = \"post\"\n",
        "\n",
        "X_fit_ids, X_test_ids = input_ids_en[fit_idx], input_ids_en[test_idx]\n",
        "X_fit_mask, X_test_mask = attention_mask_en[fit_idx], attention_mask_en[test_idx]\n",
        "X_fit_aux, X_test_aux = X_aux_en[fit_idx], X_aux_en[test_idx]\n",
        "y_fit, y_test = y_en[fit_idx], y_en[test_idx]\n",
        "\n",
        "X_val_ids = input_ids_en[val_idx] if len(val_idx) else None\n",
        "X_val_mask = attention_mask_en[val_idx] if len(val_idx) else None\n",
        "X_val_aux = X_aux_en[val_idx] if len(val_idx) else None\n",
        "y_val = y_en[val_idx] if len(val_idx) else None\n",
        "\n",
        "fit_author_ids = np.unique(train_en_model.iloc[fit_idx][\"author_id\"].to_numpy())\n",
        "val_author_ids = np.unique(train_en_model.iloc[val_idx][\"author_id\"].to_numpy()) if len(val_idx) else np.array([])\n",
        "test_author_ids = np.unique(train_en_model.iloc[test_idx][\"author_id\"].to_numpy())\n",
        "\n",
        "class_weight_dict = None\n",
        "if USE_CLASS_WEIGHTS:\n",
        "    classes = np.unique(y_fit)\n",
        "    class_weights = compute_class_weight(class_weight=\"balanced\", classes=classes, y=y_fit)\n",
        "    class_weight_dict = {int(c): float(w) for c, w in zip(classes, class_weights)}\n",
        "\n",
        "\n",
        "def build_multifeature_model(\n",
        "    vocab_size,\n",
        "    seq_len,\n",
        "    aux_dim,\n",
        "    embedding_dim,\n",
        "    gru_units,\n",
        "    aux_dense_units,\n",
        "    head_dense_units,\n",
        "    dropout_text,\n",
        "    dropout_aux,\n",
        "    dropout_head,\n",
        "    learning_rate,\n",
        "):\n",
        "    ids_input = tf.keras.layers.Input(shape=(seq_len,), dtype=\"int32\", name=\"input_ids\")\n",
        "    mask_input = tf.keras.layers.Input(shape=(seq_len,), dtype=\"float32\", name=\"attention_mask\")\n",
        "    aux_input = tf.keras.layers.Input(shape=(aux_dim,), dtype=\"float32\", name=\"aux_features\")\n",
        "\n",
        "    x = tf.keras.layers.Embedding(vocab_size, embedding_dim, name=\"token_embedding\")(ids_input)\n",
        "    mask = tf.keras.layers.Reshape((seq_len, 1))(mask_input)\n",
        "    x = tf.keras.layers.Multiply()([x, mask])\n",
        "    x = tf.keras.layers.Bidirectional(tf.keras.layers.GRU(gru_units))(x)\n",
        "    x = tf.keras.layers.Dropout(dropout_text)(x)\n",
        "\n",
        "    aux = tf.keras.layers.Dense(aux_dense_units, activation=\"relu\")(aux_input)\n",
        "    aux = tf.keras.layers.Dropout(dropout_aux)(aux)\n",
        "\n",
        "    merged = tf.keras.layers.Concatenate()([x, aux])\n",
        "    merged = tf.keras.layers.Dense(head_dense_units, activation=\"relu\")(merged)\n",
        "    merged = tf.keras.layers.Dropout(dropout_head)(merged)\n",
        "    output = tf.keras.layers.Dense(1, activation=\"sigmoid\")(merged)\n",
        "\n",
        "    model = tf.keras.Model(inputs=[ids_input, mask_input, aux_input], outputs=output)\n",
        "    model.compile(\n",
        "        optimizer=tf.keras.optimizers.Adam(learning_rate=learning_rate),\n",
        "        loss=\"binary_crossentropy\",\n",
        "        metrics=[tf.keras.metrics.BinaryAccuracy(name=\"accuracy\"), tf.keras.metrics.AUC(name=\"auc\")],\n",
        "    )\n",
        "    return model\n",
        "\n",
        "\n",
        "model_en = build_multifeature_model(\n",
        "    vocab_size=tokenizer.vocab_size,\n",
        "    seq_len=MAX_LENGTH,\n",
        "    aux_dim=X_fit_aux.shape[1],\n",
        "    embedding_dim=EMBEDDING_DIM,\n",
        "    gru_units=GRU_UNITS,\n",
        "    aux_dense_units=AUX_DENSE_UNITS,\n",
        "    head_dense_units=HEAD_DENSE_UNITS,\n",
        "    dropout_text=DROPOUT_TEXT,\n",
        "    dropout_aux=DROPOUT_AUX,\n",
        "    dropout_head=DROPOUT_HEAD,\n",
        "    learning_rate=LEARNING_RATE,\n",
        ")\n",
        "\n",
        "has_validation = len(val_idx) > 0\n",
        "callbacks = []\n",
        "if has_validation and EARLY_STOPPING_PATIENCE > 0:\n",
        "    callbacks.append(\n",
        "        tf.keras.callbacks.EarlyStopping(\n",
        "            monitor=\"val_auc\",\n",
        "            mode=\"max\",\n",
        "            patience=EARLY_STOPPING_PATIENCE,\n",
        "            restore_best_weights=True,\n",
        "        )\n",
        "    )\n",
        "if has_validation and REDUCE_LR_PATIENCE > 0:\n",
        "    callbacks.append(\n",
        "        tf.keras.callbacks.ReduceLROnPlateau(\n",
        "            monitor=\"val_auc\",\n",
        "            mode=\"max\",\n",
        "            factor=REDUCE_LR_FACTOR,\n",
        "            patience=REDUCE_LR_PATIENCE,\n",
        "            min_lr=REDUCE_LR_MIN_LR,\n",
        "        )\n",
        "    )\n",
        "\n",
        "train_inputs = {\n",
        "    \"input_ids\": X_fit_ids,\n",
        "    \"attention_mask\": X_fit_mask,\n",
        "    \"aux_features\": X_fit_aux,\n",
        "}\n",
        "\n",
        "fit_kwargs = {\n",
        "    \"epochs\": EPOCHS,\n",
        "    \"batch_size\": BATCH_SIZE,\n",
        "    \"class_weight\": class_weight_dict,\n",
        "    \"callbacks\": callbacks,\n",
        "    \"verbose\": 1,\n",
        "}\n",
        "if has_validation:\n",
        "    fit_kwargs[\"validation_data\"] = (\n",
        "        {\n",
        "            \"input_ids\": X_val_ids,\n",
        "            \"attention_mask\": X_val_mask,\n",
        "            \"aux_features\": X_val_aux,\n",
        "        },\n",
        "        y_val,\n",
        "    )\n",
        "\n",
        "history_en = model_en.fit(train_inputs, y_fit, **fit_kwargs)\n",
        "\n",
        "post_prob_fit = predict_for_indices(model_en, fit_idx)\n",
        "post_prob_val = predict_for_indices(model_en, val_idx)\n",
        "post_prob_test = predict_for_indices(model_en, test_idx)\n",
        "\n",
        "y_prob = post_prob_test.copy()\n",
        "threshold_search_results_en = pd.DataFrame()\n",
        "SELECTED_THRESHOLD = PREDICTION_THRESHOLD\n",
        "best_threshold_val_score = None\n",
        "\n",
        "if has_validation and USE_THRESHOLD_SEARCH:\n",
        "    val_author_ids_for_score = train_en_model.iloc[val_idx][\"author_id\"].to_numpy()\n",
        "    search_rows = []\n",
        "    for threshold in np.linspace(THRESHOLD_SEARCH_MIN, THRESHOLD_SEARCH_MAX, THRESHOLD_SEARCH_STEPS):\n",
        "        score, tp_acc, fn_acc, fp_acc, n_accounts = compute_account_score(\n",
        "            author_ids=val_author_ids_for_score,\n",
        "            true_labels=y_val,\n",
        "            pred_probs=post_prob_val,\n",
        "            threshold=float(threshold),\n",
        "            decision_rule=ACCOUNT_DECISION_RULE,\n",
        "        )\n",
        "        search_rows.append(\n",
        "            {\n",
        "                \"threshold\": float(threshold),\n",
        "                \"score\": int(score),\n",
        "                \"tp_accounts\": int(tp_acc),\n",
        "                \"fn_accounts\": int(fn_acc),\n",
        "                \"fp_accounts\": int(fp_acc),\n",
        "                \"n_accounts\": int(n_accounts),\n",
        "            }\n",
        "        )\n",
        "\n",
        "    threshold_search_results_en = pd.DataFrame(search_rows)\n",
        "    best_row = threshold_search_results_en.sort_values(\n",
        "        by=[\"score\", \"fp_accounts\", \"tp_accounts\", \"threshold\"],\n",
        "        ascending=[False, True, False, False],\n",
        "    ).iloc[0]\n",
        "\n",
        "    SELECTED_THRESHOLD = float(best_row[\"threshold\"])\n",
        "    best_threshold_val_score = int(best_row[\"score\"])\n",
        "\n",
        "y_pred = (y_prob >= SELECTED_THRESHOLD).astype(np.int64)\n",
        "\n",
        "test_author_ids_for_score = train_en_model.iloc[test_idx][\"author_id\"].to_numpy()\n",
        "(\n",
        "    test_score,\n",
        "    test_tp_accounts,\n",
        "    test_fn_accounts,\n",
        "    test_fp_accounts,\n",
        "    test_n_accounts,\n",
        ") = compute_account_score(\n",
        "    author_ids=test_author_ids_for_score,\n",
        "    true_labels=y_test,\n",
        "    pred_probs=y_prob,\n",
        "    threshold=SELECTED_THRESHOLD,\n",
        "    decision_rule=ACCOUNT_DECISION_RULE,\n",
        ")\n",
        "\n",
        "(\n",
        "    baseline_test_score,\n",
        "    baseline_tp_accounts,\n",
        "    baseline_fn_accounts,\n",
        "    baseline_fp_accounts,\n",
        "    baseline_n_accounts,\n",
        ") = compute_account_score(\n",
        "    author_ids=test_author_ids_for_score,\n",
        "    true_labels=y_test,\n",
        "    pred_probs=y_prob,\n",
        "    threshold=PREDICTION_THRESHOLD,\n",
        "    decision_rule=ACCOUNT_DECISION_RULE,\n",
        ")\n",
        "\n",
        "print(f\"Split mode: {split_mode}\")\n",
        "print(f\"Topic features enabled: {USE_TOPIC_FEATURES}\")\n",
        "print(f\"Topic match mode: {TOPIC_MATCH_MODE}\")\n",
        "print(f\"Account decision rule: {ACCOUNT_DECISION_RULE}\")\n",
        "print(\"Topic columns:\", topic_feature_cols_en)\n",
        "print(f\"Split sizes (fit/val/test posts): {len(fit_idx)}/{len(val_idx)}/{len(test_idx)}\")\n",
        "print(\n",
        "    f\"Split sizes (fit/val/test accounts): {len(fit_author_ids)}/{len(val_author_ids)}/{len(test_author_ids)}\"\n",
        ")\n",
        "print(f\"Default threshold from config: {PREDICTION_THRESHOLD:.4f}\")\n",
        "print(f\"Selected threshold used on test: {SELECTED_THRESHOLD:.4f}\")\n",
        "if best_threshold_val_score is not None:\n",
        "    print(f\"Best validation score from threshold search: {best_threshold_val_score}\")\n",
        "print(f\"Test Accuracy (post-level): {accuracy_score(y_test, y_pred):.4f}\")\n",
        "print(f\"Test ROC-AUC (post-level): {roc_auc_score(y_test, y_prob):.4f}\")\n",
        "print(\n",
        "    f\"Test account score @ selected threshold -> score={test_score}, TP={test_tp_accounts}, FN={test_fn_accounts}, FP={test_fp_accounts}, accounts={test_n_accounts}\"\n",
        ")\n",
        "print(\n",
        "    f\"Test account score @ config threshold -> score={baseline_test_score}, TP={baseline_tp_accounts}, FN={baseline_fn_accounts}, FP={baseline_fp_accounts}, accounts={baseline_n_accounts}\"\n",
        ")\n",
        "print(classification_report(y_test, y_pred, digits=4))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b0a6a2a8",
      "metadata": {},
      "source": [
        "## Bot-detector score"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 67,
      "id": "e84ff0e0",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Threshold used: 0.2650\n",
            "Account decision rule: mean\n",
            "Accounts scored (test split): 110\n",
            "TP: 22  FN: 4  FP: 11  TN: 73\n",
            "Bot detector score: 62\n",
            "Score out of max possible: 62/104 (59.62%)\n",
            "Score range on this split: [-194, 104]\n",
            "Range-normalized score: 85.91%\n",
            "Second-stage account-model score (recommended): 92 at threshold 0.7050\n"
          ]
        }
      ],
      "source": [
        "if any(name not in globals() for name in [\"train_en_model\", \"test_idx\", \"y_prob\", \"PREDICTION_THRESHOLD\"]):\n",
        "    raise ValueError(\"Run the Train-Test split for model cell first.\")\n",
        "\n",
        "threshold_for_score = float(globals().get(\"SELECTED_THRESHOLD\", PREDICTION_THRESHOLD))\n",
        "if \"ACCOUNT_DECISION_RULE\" in globals():\n",
        "    account_decision_rule = str(ACCOUNT_DECISION_RULE)\n",
        "elif \"EXPERIMENT_CONFIG\" in globals():\n",
        "    account_decision_rule = str(EXPERIMENT_CONFIG.get(\"account_decision_rule\", \"mean\"))\n",
        "else:\n",
        "    account_decision_rule = \"mean\"\n",
        "\n",
        "if account_decision_rule not in {\"mean\", \"any\"}:\n",
        "    raise ValueError('account_decision_rule must be \"mean\" or \"any\".')\n",
        "\n",
        "# Build test-set account labels/predictions from post-level outputs.\n",
        "score_df = train_en_model.iloc[test_idx][[\"author_id\", \"is_bot\"]].copy()\n",
        "score_df[\"pred_prob\"] = y_prob\n",
        "score_df[\"pred_post\"] = (score_df[\"pred_prob\"] >= threshold_for_score).astype(np.int64)\n",
        "\n",
        "account_df = (\n",
        "    score_df.groupby(\"author_id\", as_index=False)\n",
        "    .agg(\n",
        "        true_is_bot=(\"is_bot\", \"max\"),\n",
        "        mean_prob=(\"pred_prob\", \"mean\"),\n",
        "        any_pred=(\"pred_post\", \"max\"),\n",
        "        n_posts=(\"pred_post\", \"size\"),\n",
        "    )\n",
        ")\n",
        "\n",
        "if account_decision_rule == \"any\":\n",
        "    account_df[\"pred_is_bot\"] = account_df[\"any_pred\"].astype(np.int64)\n",
        "else:\n",
        "    account_df[\"pred_is_bot\"] = (account_df[\"mean_prob\"] >= threshold_for_score).astype(np.int64)\n",
        "\n",
        "tp_accounts = int(((account_df[\"true_is_bot\"] == 1) & (account_df[\"pred_is_bot\"] == 1)).sum())\n",
        "fn_accounts = int(((account_df[\"true_is_bot\"] == 1) & (account_df[\"pred_is_bot\"] == 0)).sum())\n",
        "fp_accounts = int(((account_df[\"true_is_bot\"] == 0) & (account_df[\"pred_is_bot\"] == 1)).sum())\n",
        "tn_accounts = int(((account_df[\"true_is_bot\"] == 0) & (account_df[\"pred_is_bot\"] == 0)).sum())\n",
        "\n",
        "score = (4 * tp_accounts) - (1 * fn_accounts) - (2 * fp_accounts)\n",
        "max_possible_score = 4 * int((account_df[\"true_is_bot\"] == 1).sum())\n",
        "min_possible_score = (\n",
        "    -1 * int((account_df[\"true_is_bot\"] == 1).sum())\n",
        "    -2 * int((account_df[\"true_is_bot\"] == 0).sum())\n",
        ")\n",
        "\n",
        "score_ratio = score / max_possible_score if max_possible_score > 0 else np.nan\n",
        "score_normalized = (\n",
        "    (score - min_possible_score) / (max_possible_score - min_possible_score)\n",
        "    if max_possible_score != min_possible_score\n",
        "    else np.nan\n",
        ")\n",
        "\n",
        "print(f\"Threshold used: {threshold_for_score:.4f}\")\n",
        "print(f\"Account decision rule: {account_decision_rule}\")\n",
        "print(f\"Accounts scored (test split): {len(account_df)}\")\n",
        "print(f\"TP: {tp_accounts}  FN: {fn_accounts}  FP: {fp_accounts}  TN: {tn_accounts}\")\n",
        "print(f\"Bot detector score: {score}\")\n",
        "print(f\"Score out of max possible: {score}/{max_possible_score} ({score_ratio:.2%})\")\n",
        "print(f\"Score range on this split: [{min_possible_score}, {max_possible_score}]\")\n",
        "print(f\"Range-normalized score: {score_normalized:.2%}\")\n",
        "\n",
        "if \"second_stage_test_score_en\" in globals():\n",
        "    print(\n",
        "        f\"Second-stage account-model score (recommended): {second_stage_test_score_en} at threshold {second_stage_selected_threshold_en:.4f}\"\n",
        "    )\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "9a2db3f5",
      "metadata": {},
      "source": [
        "## Strongest booster (account-level second stage)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 68,
      "id": "a1c7e2d9",
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2026-02-08 16:51:40.532111: E tensorflow/core/framework/node_def_util.cc:680] NodeDef mentions attribute use_unbounded_threadpool which is not in the op definition: Op<name=MapDataset; signature=input_dataset:variant, other_arguments: -> handle:variant; attr=f:func; attr=Targuments:list(type),min=0; attr=output_types:list(type),min=1; attr=output_shapes:list(shape),min=1; attr=use_inter_op_parallelism:bool,default=true; attr=preserve_cardinality:bool,default=false; attr=force_synchronous:bool,default=false; attr=metadata:string,default=\"\"> This may be expected if your graph generating binary is newer  than this binary. Unknown attributes will be ignored. NodeDef: {{node ParallelMapDatasetV2/_17}}\n",
            "2026-02-08 16:51:50.027853: E tensorflow/core/framework/node_def_util.cc:680] NodeDef mentions attribute use_unbounded_threadpool which is not in the op definition: Op<name=MapDataset; signature=input_dataset:variant, other_arguments: -> handle:variant; attr=f:func; attr=Targuments:list(type),min=0; attr=output_types:list(type),min=1; attr=output_shapes:list(shape),min=1; attr=use_inter_op_parallelism:bool,default=true; attr=preserve_cardinality:bool,default=false; attr=force_synchronous:bool,default=false; attr=metadata:string,default=\"\"> This may be expected if your graph generating binary is newer  than this binary. Unknown attributes will be ignored. NodeDef: {{node ParallelMapDatasetV2/_17}}\n",
            "2026-02-08 16:51:59.733288: E tensorflow/core/framework/node_def_util.cc:680] NodeDef mentions attribute use_unbounded_threadpool which is not in the op definition: Op<name=MapDataset; signature=input_dataset:variant, other_arguments: -> handle:variant; attr=f:func; attr=Targuments:list(type),min=0; attr=output_types:list(type),min=1; attr=output_shapes:list(shape),min=1; attr=use_inter_op_parallelism:bool,default=true; attr=preserve_cardinality:bool,default=false; attr=force_synchronous:bool,default=false; attr=metadata:string,default=\"\"> This may be expected if your graph generating binary is newer  than this binary. Unknown attributes will be ignored. NodeDef: {{node ParallelMapDatasetV2/_16}}\n",
            "2026-02-08 16:52:05.285773: E tensorflow/core/framework/node_def_util.cc:680] NodeDef mentions attribute use_unbounded_threadpool which is not in the op definition: Op<name=MapDataset; signature=input_dataset:variant, other_arguments: -> handle:variant; attr=f:func; attr=Targuments:list(type),min=0; attr=output_types:list(type),min=1; attr=output_shapes:list(shape),min=1; attr=use_inter_op_parallelism:bool,default=true; attr=preserve_cardinality:bool,default=false; attr=force_synchronous:bool,default=false; attr=metadata:string,default=\"\"> This may be expected if your graph generating binary is newer  than this binary. Unknown attributes will be ignored. NodeDef: {{node ParallelMapDatasetV2/_17}}\n",
            "2026-02-08 16:52:13.733891: E tensorflow/core/framework/node_def_util.cc:680] NodeDef mentions attribute use_unbounded_threadpool which is not in the op definition: Op<name=MapDataset; signature=input_dataset:variant, other_arguments: -> handle:variant; attr=f:func; attr=Targuments:list(type),min=0; attr=output_types:list(type),min=1; attr=output_shapes:list(shape),min=1; attr=use_inter_op_parallelism:bool,default=true; attr=preserve_cardinality:bool,default=false; attr=force_synchronous:bool,default=false; attr=metadata:string,default=\"\"> This may be expected if your graph generating binary is newer  than this binary. Unknown attributes will be ignored. NodeDef: {{node ParallelMapDatasetV2/_17}}\n",
            "2026-02-08 16:52:23.125407: E tensorflow/core/framework/node_def_util.cc:680] NodeDef mentions attribute use_unbounded_threadpool which is not in the op definition: Op<name=MapDataset; signature=input_dataset:variant, other_arguments: -> handle:variant; attr=f:func; attr=Targuments:list(type),min=0; attr=output_types:list(type),min=1; attr=output_shapes:list(shape),min=1; attr=use_inter_op_parallelism:bool,default=true; attr=preserve_cardinality:bool,default=false; attr=force_synchronous:bool,default=false; attr=metadata:string,default=\"\"> This may be expected if your graph generating binary is newer  than this binary. Unknown attributes will be ignored. NodeDef: {{node ParallelMapDatasetV2/_16}}\n",
            "2026-02-08 16:52:28.877070: E tensorflow/core/framework/node_def_util.cc:680] NodeDef mentions attribute use_unbounded_threadpool which is not in the op definition: Op<name=MapDataset; signature=input_dataset:variant, other_arguments: -> handle:variant; attr=f:func; attr=Targuments:list(type),min=0; attr=output_types:list(type),min=1; attr=output_shapes:list(shape),min=1; attr=use_inter_op_parallelism:bool,default=true; attr=preserve_cardinality:bool,default=false; attr=force_synchronous:bool,default=false; attr=metadata:string,default=\"\"> This may be expected if your graph generating binary is newer  than this binary. Unknown attributes will be ignored. NodeDef: {{node ParallelMapDatasetV2/_17}}\n",
            "2026-02-08 16:52:37.728353: E tensorflow/core/framework/node_def_util.cc:680] NodeDef mentions attribute use_unbounded_threadpool which is not in the op definition: Op<name=MapDataset; signature=input_dataset:variant, other_arguments: -> handle:variant; attr=f:func; attr=Targuments:list(type),min=0; attr=output_types:list(type),min=1; attr=output_shapes:list(shape),min=1; attr=use_inter_op_parallelism:bool,default=true; attr=preserve_cardinality:bool,default=false; attr=force_synchronous:bool,default=false; attr=metadata:string,default=\"\"> This may be expected if your graph generating binary is newer  than this binary. Unknown attributes will be ignored. NodeDef: {{node ParallelMapDatasetV2/_17}}\n",
            "2026-02-08 16:52:47.356329: E tensorflow/core/framework/node_def_util.cc:680] NodeDef mentions attribute use_unbounded_threadpool which is not in the op definition: Op<name=MapDataset; signature=input_dataset:variant, other_arguments: -> handle:variant; attr=f:func; attr=Targuments:list(type),min=0; attr=output_types:list(type),min=1; attr=output_shapes:list(shape),min=1; attr=use_inter_op_parallelism:bool,default=true; attr=preserve_cardinality:bool,default=false; attr=force_synchronous:bool,default=false; attr=metadata:string,default=\"\"> This may be expected if your graph generating binary is newer  than this binary. Unknown attributes will be ignored. NodeDef: {{node ParallelMapDatasetV2/_16}}\n",
            "2026-02-08 16:52:52.828722: E tensorflow/core/framework/node_def_util.cc:680] NodeDef mentions attribute use_unbounded_threadpool which is not in the op definition: Op<name=MapDataset; signature=input_dataset:variant, other_arguments: -> handle:variant; attr=f:func; attr=Targuments:list(type),min=0; attr=output_types:list(type),min=1; attr=output_shapes:list(shape),min=1; attr=use_inter_op_parallelism:bool,default=true; attr=preserve_cardinality:bool,default=false; attr=force_synchronous:bool,default=false; attr=metadata:string,default=\"\"> This may be expected if your graph generating binary is newer  than this binary. Unknown attributes will be ignored. NodeDef: {{node ParallelMapDatasetV2/_17}}\n",
            "2026-02-08 16:53:01.788110: E tensorflow/core/framework/node_def_util.cc:680] NodeDef mentions attribute use_unbounded_threadpool which is not in the op definition: Op<name=MapDataset; signature=input_dataset:variant, other_arguments: -> handle:variant; attr=f:func; attr=Targuments:list(type),min=0; attr=output_types:list(type),min=1; attr=output_shapes:list(shape),min=1; attr=use_inter_op_parallelism:bool,default=true; attr=preserve_cardinality:bool,default=false; attr=force_synchronous:bool,default=false; attr=metadata:string,default=\"\"> This may be expected if your graph generating binary is newer  than this binary. Unknown attributes will be ignored. NodeDef: {{node ParallelMapDatasetV2/_17}}\n",
            "2026-02-08 16:53:11.745936: E tensorflow/core/framework/node_def_util.cc:680] NodeDef mentions attribute use_unbounded_threadpool which is not in the op definition: Op<name=MapDataset; signature=input_dataset:variant, other_arguments: -> handle:variant; attr=f:func; attr=Targuments:list(type),min=0; attr=output_types:list(type),min=1; attr=output_shapes:list(shape),min=1; attr=use_inter_op_parallelism:bool,default=true; attr=preserve_cardinality:bool,default=false; attr=force_synchronous:bool,default=false; attr=metadata:string,default=\"\"> This may be expected if your graph generating binary is newer  than this binary. Unknown attributes will be ignored. NodeDef: {{node ParallelMapDatasetV2/_16}}\n",
            "2026-02-08 16:53:17.343604: E tensorflow/core/framework/node_def_util.cc:680] NodeDef mentions attribute use_unbounded_threadpool which is not in the op definition: Op<name=MapDataset; signature=input_dataset:variant, other_arguments: -> handle:variant; attr=f:func; attr=Targuments:list(type),min=0; attr=output_types:list(type),min=1; attr=output_shapes:list(shape),min=1; attr=use_inter_op_parallelism:bool,default=true; attr=preserve_cardinality:bool,default=false; attr=force_synchronous:bool,default=false; attr=metadata:string,default=\"\"> This may be expected if your graph generating binary is newer  than this binary. Unknown attributes will be ignored. NodeDef: {{node ParallelMapDatasetV2/_17}}\n",
            "2026-02-08 16:53:27.214493: E tensorflow/core/framework/node_def_util.cc:680] NodeDef mentions attribute use_unbounded_threadpool which is not in the op definition: Op<name=MapDataset; signature=input_dataset:variant, other_arguments: -> handle:variant; attr=f:func; attr=Targuments:list(type),min=0; attr=output_types:list(type),min=1; attr=output_shapes:list(shape),min=1; attr=use_inter_op_parallelism:bool,default=true; attr=preserve_cardinality:bool,default=false; attr=force_synchronous:bool,default=false; attr=metadata:string,default=\"\"> This may be expected if your graph generating binary is newer  than this binary. Unknown attributes will be ignored. NodeDef: {{node ParallelMapDatasetV2/_17}}\n",
            "2026-02-08 16:53:37.505364: E tensorflow/core/framework/node_def_util.cc:680] NodeDef mentions attribute use_unbounded_threadpool which is not in the op definition: Op<name=MapDataset; signature=input_dataset:variant, other_arguments: -> handle:variant; attr=f:func; attr=Targuments:list(type),min=0; attr=output_types:list(type),min=1; attr=output_shapes:list(shape),min=1; attr=use_inter_op_parallelism:bool,default=true; attr=preserve_cardinality:bool,default=false; attr=force_synchronous:bool,default=false; attr=metadata:string,default=\"\"> This may be expected if your graph generating binary is newer  than this binary. Unknown attributes will be ignored. NodeDef: {{node ParallelMapDatasetV2/_16}}\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Seed-level first-stage account scores (test):\n",
            " seed  threshold  test_score  tp_accounts  fn_accounts  fp_accounts\n",
            "   13      0.335          72           20            6            1\n",
            "   29      0.325          69           21            5            5\n",
            "   42      0.520          49           15           11            0\n",
            "   73      0.660          57           17            9            1\n",
            "  101      0.380          66           20            6            4\n",
            "Seed score mean/std: 62.60 / 9.45\n",
            "Ensemble aggregation: mean\n",
            "Ensemble selected threshold: 0.3700\n",
            "Ensemble test score: 77 (TP=21, FN=5, FP=1, accounts=110)\n",
            "Second-stage model: CatBoostClassifier\n",
            "Second-stage threshold: 0.7900\n",
            "Second-stage test score: 89/104 (85.58%)\n",
            "Second-stage confusion components -> TP=23, FN=3, FP=0\n",
            "Second-stage precision=1.0000, recall=0.8846\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0     0.9655    1.0000    0.9825        84\n",
            "           1     1.0000    0.8846    0.9388        26\n",
            "\n",
            "    accuracy                         0.9727       110\n",
            "   macro avg     0.9828    0.9423    0.9606       110\n",
            "weighted avg     0.9737    0.9727    0.9721       110\n",
            "\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.metrics import classification_report, precision_score, recall_score\n",
        "\n",
        "try:\n",
        "    from catboost import CatBoostClassifier\n",
        "except ImportError as exc:\n",
        "    raise ImportError(\"Install catboost first: pip install catboost\") from exc\n",
        "\n",
        "required_globals = [\n",
        "    \"tf\",\n",
        "    \"EXPERIMENT_CONFIG\",\n",
        "    \"build_multifeature_model\",\n",
        "    \"compute_account_score\",\n",
        "    \"train_en_model\",\n",
        "    \"topic_feature_cols_en\",\n",
        "    \"fit_idx\",\n",
        "    \"val_idx\",\n",
        "    \"test_idx\",\n",
        "    \"input_ids_en\",\n",
        "    \"attention_mask_en\",\n",
        "    \"X_aux_en\",\n",
        "    \"y_en\",\n",
        "    \"MAX_LENGTH\",\n",
        "    \"tokenizer\",\n",
        "    \"users_en\",\n",
        "    \"EMBEDDING_DIM\",\n",
        "    \"GRU_UNITS\",\n",
        "    \"AUX_DENSE_UNITS\",\n",
        "    \"HEAD_DENSE_UNITS\",\n",
        "    \"DROPOUT_TEXT\",\n",
        "    \"DROPOUT_AUX\",\n",
        "    \"DROPOUT_HEAD\",\n",
        "    \"LEARNING_RATE\",\n",
        "    \"EPOCHS\",\n",
        "    \"BATCH_SIZE\",\n",
        "    \"RANDOM_SEED\",\n",
        "    \"USE_CLASS_WEIGHTS\",\n",
        "    \"class_weight_dict\",\n",
        "    \"USE_THRESHOLD_SEARCH\",\n",
        "    \"THRESHOLD_SEARCH_MIN\",\n",
        "    \"THRESHOLD_SEARCH_MAX\",\n",
        "    \"THRESHOLD_SEARCH_STEPS\",\n",
        "    \"PREDICTION_THRESHOLD\",\n",
        "    \"ACCOUNT_DECISION_RULE\",\n",
        "    \"EARLY_STOPPING_PATIENCE\",\n",
        "    \"REDUCE_LR_PATIENCE\",\n",
        "    \"REDUCE_LR_FACTOR\",\n",
        "    \"REDUCE_LR_MIN_LR\",\n",
        "]\n",
        "missing = [name for name in required_globals if name not in globals()]\n",
        "if missing:\n",
        "    raise ValueError(f\"Run the Train-Test split for model cell first. Missing: {missing}\")\n",
        "\n",
        "if ACCOUNT_DECISION_RULE not in {\"mean\", \"any\"}:\n",
        "    raise ValueError('account_decision_rule must be \"mean\" or \"any\".')\n",
        "\n",
        "ensemble_seeds_cfg = EXPERIMENT_CONFIG.get(\"ensemble_seeds\", [RANDOM_SEED])\n",
        "if isinstance(ensemble_seeds_cfg, (int, np.integer)):\n",
        "    ensemble_seeds = [int(ensemble_seeds_cfg)]\n",
        "elif isinstance(ensemble_seeds_cfg, (list, tuple)):\n",
        "    ensemble_seeds = [int(seed) for seed in ensemble_seeds_cfg]\n",
        "else:\n",
        "    raise ValueError(\"ensemble_seeds must be an int or a list of ints.\")\n",
        "ensemble_seeds = list(dict.fromkeys(ensemble_seeds))\n",
        "if not ensemble_seeds:\n",
        "    raise ValueError(\"ensemble_seeds cannot be empty.\")\n",
        "\n",
        "ENSEMBLE_AGGREGATION = str(EXPERIMENT_CONFIG.get(\"ensemble_aggregation\", \"mean\")).lower()\n",
        "if ENSEMBLE_AGGREGATION not in {\"mean\", \"median\"}:\n",
        "    raise ValueError('ensemble_aggregation must be \"mean\" or \"median\".')\n",
        "\n",
        "USE_SECOND_STAGE_ACCOUNT_MODEL = bool(EXPERIMENT_CONFIG.get(\"use_second_stage_account_model\", True))\n",
        "SECOND_STAGE_LEARNING_RATE = float(EXPERIMENT_CONFIG.get(\"second_stage_learning_rate\", 0.05))\n",
        "SECOND_STAGE_MAX_ITER = int(EXPERIMENT_CONFIG.get(\"second_stage_max_iter\", 300))\n",
        "SECOND_STAGE_MAX_DEPTH = int(EXPERIMENT_CONFIG.get(\"second_stage_max_depth\", 4))\n",
        "SECOND_STAGE_L2 = float(EXPERIMENT_CONFIG.get(\"second_stage_l2\", 0.2))\n",
        "SECOND_STAGE_USE_BALANCED_WEIGHTS = bool(EXPERIMENT_CONFIG.get(\"second_stage_use_balanced_weights\", True))\n",
        "\n",
        "has_validation = len(val_idx) > 0\n",
        "fit_author_ids_for_score = train_en_model.iloc[fit_idx][\"author_id\"].to_numpy()\n",
        "val_author_ids_for_score = train_en_model.iloc[val_idx][\"author_id\"].to_numpy() if has_validation else np.array([])\n",
        "test_author_ids_for_score = train_en_model.iloc[test_idx][\"author_id\"].to_numpy()\n",
        "\n",
        "\n",
        "def _predict_post_probs(model, indices):\n",
        "    if len(indices) == 0:\n",
        "        return np.array([], dtype=np.float32)\n",
        "    return model.predict(\n",
        "        {\n",
        "            \"input_ids\": input_ids_en[indices],\n",
        "            \"attention_mask\": attention_mask_en[indices],\n",
        "            \"aux_features\": X_aux_en[indices],\n",
        "        },\n",
        "        verbose=0,\n",
        "    ).ravel()\n",
        "\n",
        "\n",
        "def _build_callbacks():\n",
        "    callbacks = []\n",
        "    if has_validation and EARLY_STOPPING_PATIENCE > 0:\n",
        "        callbacks.append(\n",
        "            tf.keras.callbacks.EarlyStopping(\n",
        "                monitor=\"val_auc\",\n",
        "                mode=\"max\",\n",
        "                patience=EARLY_STOPPING_PATIENCE,\n",
        "                restore_best_weights=True,\n",
        "            )\n",
        "        )\n",
        "    if has_validation and REDUCE_LR_PATIENCE > 0:\n",
        "        callbacks.append(\n",
        "            tf.keras.callbacks.ReduceLROnPlateau(\n",
        "                monitor=\"val_auc\",\n",
        "                mode=\"max\",\n",
        "                factor=REDUCE_LR_FACTOR,\n",
        "                patience=REDUCE_LR_PATIENCE,\n",
        "                min_lr=REDUCE_LR_MIN_LR,\n",
        "            )\n",
        "        )\n",
        "    return callbacks\n",
        "\n",
        "\n",
        "def _search_best_threshold(author_ids, labels, probs):\n",
        "    if not (has_validation and USE_THRESHOLD_SEARCH):\n",
        "        return float(PREDICTION_THRESHOLD), None, pd.DataFrame()\n",
        "\n",
        "    rows = []\n",
        "    for threshold in np.linspace(THRESHOLD_SEARCH_MIN, THRESHOLD_SEARCH_MAX, THRESHOLD_SEARCH_STEPS):\n",
        "        score, tp, fn, fp, n_accounts = compute_account_score(\n",
        "            author_ids=author_ids,\n",
        "            true_labels=labels,\n",
        "            pred_probs=probs,\n",
        "            threshold=float(threshold),\n",
        "            decision_rule=ACCOUNT_DECISION_RULE,\n",
        "        )\n",
        "        rows.append(\n",
        "            {\n",
        "                \"threshold\": float(threshold),\n",
        "                \"score\": int(score),\n",
        "                \"tp_accounts\": int(tp),\n",
        "                \"fn_accounts\": int(fn),\n",
        "                \"fp_accounts\": int(fp),\n",
        "                \"n_accounts\": int(n_accounts),\n",
        "            }\n",
        "        )\n",
        "\n",
        "    df = pd.DataFrame(rows)\n",
        "    best_row = df.sort_values(\n",
        "        by=[\"score\", \"fp_accounts\", \"tp_accounts\", \"threshold\"],\n",
        "        ascending=[False, True, False, False],\n",
        "    ).iloc[0]\n",
        "    return float(best_row[\"threshold\"]), int(best_row[\"score\"]), df\n",
        "\n",
        "\n",
        "fit_inputs = {\n",
        "    \"input_ids\": input_ids_en[fit_idx],\n",
        "    \"attention_mask\": attention_mask_en[fit_idx],\n",
        "    \"aux_features\": X_aux_en[fit_idx],\n",
        "}\n",
        "val_inputs = (\n",
        "    {\n",
        "        \"input_ids\": input_ids_en[val_idx],\n",
        "        \"attention_mask\": attention_mask_en[val_idx],\n",
        "        \"aux_features\": X_aux_en[val_idx],\n",
        "    }\n",
        "    if has_validation\n",
        "    else None\n",
        ")\n",
        "\n",
        "post_prob_fit_list = []\n",
        "post_prob_val_list = []\n",
        "post_prob_test_list = []\n",
        "seed_rows = []\n",
        "\n",
        "if hasattr(tf.config.experimental, \"enable_op_determinism\"):\n",
        "    try:\n",
        "        tf.config.experimental.enable_op_determinism()\n",
        "    except Exception:\n",
        "        pass\n",
        "\n",
        "for seed in ensemble_seeds:\n",
        "    tf.keras.backend.clear_session()\n",
        "    tf.keras.utils.set_random_seed(int(seed))\n",
        "    np.random.seed(int(seed))\n",
        "\n",
        "    model_seed = build_multifeature_model(\n",
        "        vocab_size=tokenizer.vocab_size,\n",
        "        seq_len=MAX_LENGTH,\n",
        "        aux_dim=X_aux_en.shape[1],\n",
        "        embedding_dim=EMBEDDING_DIM,\n",
        "        gru_units=GRU_UNITS,\n",
        "        aux_dense_units=AUX_DENSE_UNITS,\n",
        "        head_dense_units=HEAD_DENSE_UNITS,\n",
        "        dropout_text=DROPOUT_TEXT,\n",
        "        dropout_aux=DROPOUT_AUX,\n",
        "        dropout_head=DROPOUT_HEAD,\n",
        "        learning_rate=LEARNING_RATE,\n",
        "    )\n",
        "\n",
        "    fit_kwargs = {\n",
        "        \"epochs\": EPOCHS,\n",
        "        \"batch_size\": BATCH_SIZE,\n",
        "        \"class_weight\": class_weight_dict if USE_CLASS_WEIGHTS else None,\n",
        "        \"callbacks\": _build_callbacks(),\n",
        "        \"verbose\": 0,\n",
        "    }\n",
        "    if has_validation:\n",
        "        fit_kwargs[\"validation_data\"] = (val_inputs, y_en[val_idx])\n",
        "\n",
        "    model_seed.fit(fit_inputs, y_en[fit_idx], **fit_kwargs)\n",
        "\n",
        "    fit_probs = _predict_post_probs(model_seed, fit_idx)\n",
        "    val_probs = _predict_post_probs(model_seed, val_idx)\n",
        "    test_probs = _predict_post_probs(model_seed, test_idx)\n",
        "\n",
        "    threshold_seed, val_score_seed, _ = _search_best_threshold(val_author_ids_for_score, y_en[val_idx], val_probs)\n",
        "\n",
        "    test_score_seed, tp_seed, fn_seed, fp_seed, n_accounts_seed = compute_account_score(\n",
        "        author_ids=test_author_ids_for_score,\n",
        "        true_labels=y_en[test_idx],\n",
        "        pred_probs=test_probs,\n",
        "        threshold=threshold_seed,\n",
        "        decision_rule=ACCOUNT_DECISION_RULE,\n",
        "    )\n",
        "\n",
        "    seed_rows.append(\n",
        "        {\n",
        "            \"seed\": int(seed),\n",
        "            \"threshold\": float(threshold_seed),\n",
        "            \"val_best_score\": val_score_seed,\n",
        "            \"test_score\": int(test_score_seed),\n",
        "            \"tp_accounts\": int(tp_seed),\n",
        "            \"fn_accounts\": int(fn_seed),\n",
        "            \"fp_accounts\": int(fp_seed),\n",
        "            \"n_accounts\": int(n_accounts_seed),\n",
        "        }\n",
        "    )\n",
        "\n",
        "    post_prob_fit_list.append(fit_probs)\n",
        "    post_prob_val_list.append(val_probs)\n",
        "    post_prob_test_list.append(test_probs)\n",
        "\n",
        "seed_report_df = pd.DataFrame(seed_rows)\n",
        "ensemble_seed_report_en = seed_report_df.copy()\n",
        "\n",
        "def _aggregate_probabilities(prob_list, mode):\n",
        "    if not prob_list:\n",
        "        return np.array([], dtype=np.float32)\n",
        "    stack = np.vstack(prob_list)\n",
        "    if mode == \"median\":\n",
        "        return np.median(stack, axis=0).astype(np.float32)\n",
        "    return np.mean(stack, axis=0).astype(np.float32)\n",
        "\n",
        "post_prob_fit_ensemble_en = _aggregate_probabilities(post_prob_fit_list, ENSEMBLE_AGGREGATION)\n",
        "post_prob_val_ensemble_en = _aggregate_probabilities(post_prob_val_list, ENSEMBLE_AGGREGATION)\n",
        "post_prob_test_ensemble_en = _aggregate_probabilities(post_prob_test_list, ENSEMBLE_AGGREGATION)\n",
        "\n",
        "selected_threshold_ensemble, best_ensemble_val_score, threshold_search_results_ensemble_en = _search_best_threshold(\n",
        "    val_author_ids_for_score,\n",
        "    y_en[val_idx],\n",
        "    post_prob_val_ensemble_en,\n",
        ")\n",
        "\n",
        "(\n",
        "    test_score_ensemble_en,\n",
        "    ensemble_tp_accounts_en,\n",
        "    ensemble_fn_accounts_en,\n",
        "    ensemble_fp_accounts_en,\n",
        "    ensemble_n_accounts_en,\n",
        ") = compute_account_score(\n",
        "    author_ids=test_author_ids_for_score,\n",
        "    true_labels=y_en[test_idx],\n",
        "    pred_probs=post_prob_test_ensemble_en,\n",
        "    threshold=selected_threshold_ensemble,\n",
        "    decision_rule=ACCOUNT_DECISION_RULE,\n",
        ")\n",
        "\n",
        "# Make the ensemble outputs the default baseline for downstream score/plot cells.\n",
        "post_prob_fit = post_prob_fit_ensemble_en\n",
        "post_prob_val = post_prob_val_ensemble_en\n",
        "post_prob_test = post_prob_test_ensemble_en\n",
        "y_prob = post_prob_test_ensemble_en\n",
        "SELECTED_THRESHOLD = float(selected_threshold_ensemble)\n",
        "test_score = int(test_score_ensemble_en)\n",
        "test_tp_accounts = int(ensemble_tp_accounts_en)\n",
        "test_fn_accounts = int(ensemble_fn_accounts_en)\n",
        "test_fp_accounts = int(ensemble_fp_accounts_en)\n",
        "test_n_accounts = int(ensemble_n_accounts_en)\n",
        "\n",
        "seed_mean_score_en = float(seed_report_df[\"test_score\"].mean())\n",
        "seed_std_score_en = float(seed_report_df[\"test_score\"].std(ddof=1)) if len(seed_report_df) > 1 else 0.0\n",
        "\n",
        "\n",
        "def build_account_feature_table(post_indices, post_probs, bot_threshold):\n",
        "    posts = train_en_model.iloc[post_indices].copy()\n",
        "    posts[\"post_prob\"] = np.asarray(post_probs, dtype=np.float32)\n",
        "\n",
        "    posts[\"has_url_post\"] = (posts[\"url_count\"] > 0).astype(np.float32)\n",
        "    posts[\"has_mention_post\"] = (posts[\"mention_count\"] > 0).astype(np.float32)\n",
        "    posts[\"has_hashtag_post\"] = (posts[\"hashtag_count\"] > 0).astype(np.float32)\n",
        "    posts[\"pred_bot_post\"] = (posts[\"post_prob\"] >= bot_threshold).astype(np.float32)\n",
        "\n",
        "    agg_spec = {\n",
        "        \"is_bot\": [\"max\"],\n",
        "        \"text_clean\": [\"size\"],\n",
        "        \"post_prob\": [\"mean\", \"std\", \"max\", \"min\"],\n",
        "        \"char_count\": [\"mean\", \"std\", \"max\"],\n",
        "        \"word_count\": [\"mean\", \"std\", \"max\"],\n",
        "        \"url_count\": [\"mean\", \"max\"],\n",
        "        \"mention_count\": [\"mean\", \"max\"],\n",
        "        \"hashtag_count\": [\"mean\", \"max\"],\n",
        "        \"exclamation_count\": [\"mean\", \"max\"],\n",
        "        \"question_count\": [\"mean\", \"max\"],\n",
        "        \"has_url_post\": [\"mean\"],\n",
        "        \"has_mention_post\": [\"mean\"],\n",
        "        \"has_hashtag_post\": [\"mean\"],\n",
        "        \"pred_bot_post\": [\"mean\"],\n",
        "    }\n",
        "\n",
        "    for topic_col in topic_feature_cols_en:\n",
        "        agg_spec[topic_col] = [\"mean\"]\n",
        "\n",
        "    account = posts.groupby(\"author_id\", as_index=False).agg(agg_spec)\n",
        "    account.columns = [\n",
        "        \"author_id\" if col == (\"author_id\", \"\") else f\"{col[0]}_{col[1]}\"\n",
        "        for col in account.columns.to_flat_index()\n",
        "    ]\n",
        "\n",
        "    account = account.rename(columns={\"is_bot_max\": \"true_is_bot\", \"text_clean_size\": \"n_posts\"})\n",
        "    for col in [\"post_prob_std\", \"char_count_std\", \"word_count_std\"]:\n",
        "        if col in account.columns:\n",
        "            account[col] = account[col].fillna(0.0)\n",
        "    account[\"n_posts_log1p\"] = np.log1p(account[\"n_posts\"].astype(np.float32))\n",
        "\n",
        "    user_source = (\n",
        "        users_en_labeled.copy()\n",
        "        if \"users_en_labeled\" in globals()\n",
        "        else users_en.drop_duplicates(subset=\"id\", keep=\"last\").copy()\n",
        "    )\n",
        "    user_source[\"username_len\"] = user_source[\"username\"].fillna(\"\").str.len()\n",
        "    user_source[\"name_len\"] = user_source[\"name\"].fillna(\"\").str.len()\n",
        "    user_source[\"description_len\"] = user_source[\"description\"].fillna(\"\").str.len()\n",
        "    user_source[\"has_location\"] = user_source[\"location\"].fillna(\"\").str.strip().ne(\"\").astype(np.float32)\n",
        "\n",
        "    user_features = user_source[\n",
        "        [\n",
        "            \"id\",\n",
        "            \"tweet_count\",\n",
        "            \"z_score\",\n",
        "            \"username_len\",\n",
        "            \"name_len\",\n",
        "            \"description_len\",\n",
        "            \"has_location\",\n",
        "        ]\n",
        "    ].copy()\n",
        "\n",
        "    account = account.merge(user_features, left_on=\"author_id\", right_on=\"id\", how=\"left\").drop(columns=[\"id\"])\n",
        "\n",
        "    numeric_cols = [col for col in account.columns if col != \"author_id\"]\n",
        "    account[numeric_cols] = account[numeric_cols].apply(pd.to_numeric, errors=\"coerce\").fillna(0.0)\n",
        "    return account\n",
        "\n",
        "\n",
        "def score_from_account_probs(true_labels, pred_probs, threshold):\n",
        "    pred_labels = (pred_probs >= threshold).astype(np.int64)\n",
        "    tp = int(((true_labels == 1) & (pred_labels == 1)).sum())\n",
        "    fn = int(((true_labels == 1) & (pred_labels == 0)).sum())\n",
        "    fp = int(((true_labels == 0) & (pred_labels == 1)).sum())\n",
        "    score = (4 * tp) - (1 * fn) - (2 * fp)\n",
        "    return score, tp, fn, fp, pred_labels\n",
        "\n",
        "\n",
        "if USE_SECOND_STAGE_ACCOUNT_MODEL:\n",
        "    fit_account_df = build_account_feature_table(fit_idx, post_prob_fit_ensemble_en, selected_threshold_ensemble)\n",
        "    val_account_df = (\n",
        "        build_account_feature_table(val_idx, post_prob_val_ensemble_en, selected_threshold_ensemble)\n",
        "        if has_validation\n",
        "        else pd.DataFrame()\n",
        "    )\n",
        "    test_account_df = build_account_feature_table(test_idx, post_prob_test_ensemble_en, selected_threshold_ensemble)\n",
        "\n",
        "    target_col = \"true_is_bot\"\n",
        "    feature_cols_account = [col for col in fit_account_df.columns if col not in {\"author_id\", target_col}]\n",
        "\n",
        "    for df in [fit_account_df, val_account_df, test_account_df]:\n",
        "        if df.empty:\n",
        "            continue\n",
        "        missing_cols = [col for col in feature_cols_account if col not in df.columns]\n",
        "        for col in missing_cols:\n",
        "            df[col] = 0.0\n",
        "\n",
        "    X_fit_acc = fit_account_df[feature_cols_account].to_numpy(dtype=np.float32)\n",
        "    y_fit_acc = fit_account_df[target_col].to_numpy(dtype=np.int64)\n",
        "    X_test_acc = test_account_df[feature_cols_account].to_numpy(dtype=np.float32)\n",
        "    y_test_acc = test_account_df[target_col].to_numpy(dtype=np.int64)\n",
        "\n",
        "    if len(val_account_df):\n",
        "        X_val_acc = val_account_df[feature_cols_account].to_numpy(dtype=np.float32)\n",
        "        y_val_acc = val_account_df[target_col].to_numpy(dtype=np.int64)\n",
        "    else:\n",
        "        X_val_acc = np.zeros((0, len(feature_cols_account)), dtype=np.float32)\n",
        "        y_val_acc = np.zeros((0,), dtype=np.int64)\n",
        "\n",
        "    catboost_kwargs = {\n",
        "        \"iterations\": SECOND_STAGE_MAX_ITER,\n",
        "        \"learning_rate\": SECOND_STAGE_LEARNING_RATE,\n",
        "        \"depth\": SECOND_STAGE_MAX_DEPTH,\n",
        "        \"l2_leaf_reg\": SECOND_STAGE_L2,\n",
        "        \"loss_function\": \"Logloss\",\n",
        "        \"eval_metric\": \"AUC\",\n",
        "        \"random_seed\": RANDOM_SEED,\n",
        "        \"verbose\": False,\n",
        "    }\n",
        "    if SECOND_STAGE_USE_BALANCED_WEIGHTS:\n",
        "        catboost_kwargs[\"auto_class_weights\"] = \"Balanced\"\n",
        "\n",
        "    second_stage_model_en = CatBoostClassifier(**catboost_kwargs)\n",
        "\n",
        "    fit_kwargs = {}\n",
        "    if len(y_val_acc):\n",
        "        fit_kwargs[\"eval_set\"] = (X_val_acc, y_val_acc)\n",
        "        fit_kwargs[\"use_best_model\"] = True\n",
        "\n",
        "    second_stage_model_en.fit(X_fit_acc, y_fit_acc, **fit_kwargs)\n",
        "\n",
        "    second_stage_selected_threshold_en = float(selected_threshold_ensemble)\n",
        "    second_stage_threshold_search_results_en = pd.DataFrame()\n",
        "\n",
        "    if len(y_val_acc) and USE_THRESHOLD_SEARCH:\n",
        "        val_prob_acc = second_stage_model_en.predict_proba(X_val_acc)[:, 1]\n",
        "        rows = []\n",
        "        for threshold in np.linspace(THRESHOLD_SEARCH_MIN, THRESHOLD_SEARCH_MAX, THRESHOLD_SEARCH_STEPS):\n",
        "            score, tp, fn, fp, _ = score_from_account_probs(y_val_acc, val_prob_acc, float(threshold))\n",
        "            rows.append(\n",
        "                {\n",
        "                    \"threshold\": float(threshold),\n",
        "                    \"score\": int(score),\n",
        "                    \"tp_accounts\": int(tp),\n",
        "                    \"fn_accounts\": int(fn),\n",
        "                    \"fp_accounts\": int(fp),\n",
        "                }\n",
        "            )\n",
        "        second_stage_threshold_search_results_en = pd.DataFrame(rows)\n",
        "        best_row = second_stage_threshold_search_results_en.sort_values(\n",
        "            by=[\"score\", \"fp_accounts\", \"tp_accounts\", \"threshold\"],\n",
        "            ascending=[False, True, False, False],\n",
        "        ).iloc[0]\n",
        "        second_stage_selected_threshold_en = float(best_row[\"threshold\"])\n",
        "\n",
        "    second_stage_test_prob_en = second_stage_model_en.predict_proba(X_test_acc)[:, 1]\n",
        "    (\n",
        "        second_stage_test_score_en,\n",
        "        second_stage_tp_accounts_en,\n",
        "        second_stage_fn_accounts_en,\n",
        "        second_stage_fp_accounts_en,\n",
        "        second_stage_test_pred_en,\n",
        "    ) = score_from_account_probs(y_test_acc, second_stage_test_prob_en, second_stage_selected_threshold_en)\n",
        "\n",
        "    max_score_accounts = 4 * int((y_test_acc == 1).sum())\n",
        "    second_stage_score_ratio_en = (\n",
        "        second_stage_test_score_en / max_score_accounts if max_score_accounts > 0 else np.nan\n",
        "    )\n",
        "\n",
        "    second_stage_account_predictions_en = test_account_df[[\"author_id\", target_col]].copy()\n",
        "    second_stage_account_predictions_en[\"pred_prob\"] = second_stage_test_prob_en\n",
        "    second_stage_account_predictions_en[\"pred_is_bot\"] = second_stage_test_pred_en\n",
        "\n",
        "    # Make CatBoost second-stage score visible to downstream summary/plot cells.\n",
        "    max_possible_score = max_score_accounts\n",
        "\n",
        "print(\"Seed-level first-stage account scores (test):\")\n",
        "print(\n",
        "    seed_report_df[\n",
        "        [\n",
        "            \"seed\",\n",
        "            \"threshold\",\n",
        "            \"test_score\",\n",
        "            \"tp_accounts\",\n",
        "            \"fn_accounts\",\n",
        "            \"fp_accounts\",\n",
        "        ]\n",
        "    ].to_string(index=False)\n",
        ")\n",
        "print(f\"Seed score mean/std: {seed_mean_score_en:.2f} / {seed_std_score_en:.2f}\")\n",
        "print(f\"Ensemble aggregation: {ENSEMBLE_AGGREGATION}\")\n",
        "print(f\"Ensemble selected threshold: {selected_threshold_ensemble:.4f}\")\n",
        "print(\n",
        "    f\"Ensemble test score: {test_score_ensemble_en} (TP={ensemble_tp_accounts_en}, FN={ensemble_fn_accounts_en}, FP={ensemble_fp_accounts_en}, accounts={ensemble_n_accounts_en})\"\n",
        ")\n",
        "\n",
        "if USE_SECOND_STAGE_ACCOUNT_MODEL:\n",
        "    print(\"Second-stage model: CatBoostClassifier\")\n",
        "    print(\n",
        "        f\"Second-stage threshold: {second_stage_selected_threshold_en:.4f}\"\n",
        "    )\n",
        "    print(\n",
        "        f\"Second-stage test score: {second_stage_test_score_en}/{max_score_accounts} ({second_stage_score_ratio_en:.2%})\"\n",
        "    )\n",
        "    print(\n",
        "        f\"Second-stage confusion components -> TP={second_stage_tp_accounts_en}, FN={second_stage_fn_accounts_en}, FP={second_stage_fp_accounts_en}\"\n",
        "    )\n",
        "    print(\n",
        "        f\"Second-stage precision={precision_score(y_test_acc, second_stage_test_pred_en, zero_division=0):.4f}, \"\n",
        "        f\"recall={recall_score(y_test_acc, second_stage_test_pred_en, zero_division=0):.4f}\"\n",
        "    )\n",
        "    print(classification_report(y_test_acc, second_stage_test_pred_en, digits=4))\n",
        "else:\n",
        "    print(\"Second-stage account model disabled in EXPERIMENT_CONFIG.\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d26c4f9a",
      "metadata": {},
      "source": [
        "## Final score plot"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 69,
      "id": "c477e2ab",
      "metadata": {},
      "outputs": [
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 800x450 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Without booster: 77\n",
            "With booster: 89\n",
            "Competition top (max possible on this split): 104\n"
          ]
        }
      ],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "if \"train_en_model\" not in globals() or \"test_idx\" not in globals():\n",
        "    raise ValueError(\"Run the training cell first.\")\n",
        "\n",
        "score_without_booster = None\n",
        "if \"test_score\" in globals():\n",
        "    score_without_booster = float(test_score)\n",
        "elif \"score\" in globals():\n",
        "    score_without_booster = float(score)\n",
        "else:\n",
        "    raise ValueError(\"No baseline score found. Run the model scoring cells first.\")\n",
        "\n",
        "score_with_booster = float(second_stage_test_score_en) if \"second_stage_test_score_en\" in globals() else None\n",
        "\n",
        "if \"max_possible_score\" in globals():\n",
        "    competition_top = float(max_possible_score)\n",
        "else:\n",
        "    account_truth = (\n",
        "        train_en_model.iloc[test_idx][[\"author_id\", \"is_bot\"]]\n",
        "        .groupby(\"author_id\", as_index=False)[\"is_bot\"]\n",
        "        .max()\n",
        "    )\n",
        "    competition_top = float(4 * int(account_truth[\"is_bot\"].sum()))\n",
        "\n",
        "labels = [\"Without booster\"]\n",
        "scores = [score_without_booster]\n",
        "colors = [\"#4c78a8\"]\n",
        "\n",
        "if score_with_booster is not None:\n",
        "    labels.append(\"With booster\")\n",
        "    scores.append(score_with_booster)\n",
        "    colors.append(\"#f58518\")\n",
        "\n",
        "fig, ax = plt.subplots(figsize=(8, 4.5))\n",
        "bars = ax.bar(labels, scores, color=colors, alpha=0.9)\n",
        "ax.axhline(competition_top, color=\"#54a24b\", linestyle=\"--\", linewidth=2, label=f\"Competition top: {competition_top:.0f}\")\n",
        "\n",
        "for bar, value in zip(bars, scores):\n",
        "    ax.text(\n",
        "        bar.get_x() + bar.get_width() / 2,\n",
        "        value,\n",
        "        f\"{value:.0f}\",\n",
        "        ha=\"center\",\n",
        "        va=\"bottom\",\n",
        "        fontsize=10,\n",
        "        fontweight=\"bold\",\n",
        "    )\n",
        "\n",
        "ax.set_title(\"Competition Score Comparison\")\n",
        "ax.set_ylabel(\"Score\")\n",
        "ax.set_ylim(0, max(max(scores), competition_top) * 1.15)\n",
        "ax.grid(axis=\"y\", linestyle=\":\", alpha=0.4)\n",
        "ax.legend(loc=\"upper left\")\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "print(f\"Without booster: {score_without_booster:.0f}\")\n",
        "if score_with_booster is not None:\n",
        "    print(f\"With booster: {score_with_booster:.0f}\")\n",
        "print(f\"Competition top (max possible on this split): {competition_top:.0f}\")\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "venv_botsornot (3.13.0)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.13.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
